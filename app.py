# app.py

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter

# Configure the Streamlit page
st.set_page_config(page_title="Job Market Dashboard", layout="wide")
st.title("ðŸ“Š Job Market Trends Dashboard")

# Path to the CSV file generated by scraper
CSV_PATH = "linkedin_jobs.csv"

# Try loading the CSV
try:
    df = pd.read_csv(CSV_PATH)
except FileNotFoundError:
    st.error(f"'{CSV_PATH}' not found. Please run the scraper first.")
    st.stop()

# Normalize column names for safety
df.columns = [col.lower().strip() for col in df.columns]

# Show warning if less than 30 jobs are loaded
if len(df) < 30:
    st.warning(f"âš ï¸ Only {len(df)} job listings found. Please scrape at least 30 for reliable analysis.")

# Preview the raw data
st.subheader("ðŸ“„ Raw Data Preview")
st.dataframe(df.head())

# ðŸ” Top 5 Most In-Demand Job Titles
if "title" in df.columns:
    st.subheader("ðŸ” Top 5 Most In-Demand Job Titles")
    top_titles = df["title"].value_counts().head(5)
    st.bar_chart(top_titles)
else:
    st.warning("No 'title' column found.")

# ðŸ“ Cities with Most Job Openings
if "location" in df.columns:
    st.subheader("ðŸ“ Top Hiring Cities")
    top_cities = df["location"].value_counts().head(5)
    st.bar_chart(top_cities)
else:
    st.warning("No 'location' column found.")

# ðŸ“ˆ Posting Trends Over Time
if "date_posted" in df.columns:
    st.subheader("ðŸ“ˆ Job Posting Trends Over Time")
    try:
        df["date_posted"] = pd.to_datetime(df["date_posted"], errors="coerce")
        date_counts = df["date_posted"].value_counts().sort_index()
        st.line_chart(date_counts)
    except Exception as e:
        st.warning(f"Couldn't parse 'date_posted' column: {e}")
else:
    st.info("No 'date_posted' column found to display trend chart.")
